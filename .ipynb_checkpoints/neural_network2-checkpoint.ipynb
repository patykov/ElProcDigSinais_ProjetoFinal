{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### READING DATASET ###\n",
    "\n",
    "# Paths\n",
    "dataset_path = 'Dataset'\n",
    "games_dir = next(os.walk(dataset_path))[1]\n",
    "\n",
    "tag_to_skip = ['highlights', 'highlights2', '.DS_Store', '.git']\n",
    "\n",
    "# Iterating through games\n",
    "games_data = []\n",
    "games_path = [os.path.join(dataset_path, g) for g in games_dir]\n",
    "for path in games_path:\n",
    "    game_name = os.path.basename(path)\n",
    "    if game_name != 'ned_svk':\n",
    "        game_info = os.listdir(path)\n",
    "        data = collections.OrderedDict()\n",
    "        for info in game_info:\n",
    "            tag_name = os.path.splitext(info)[0]\n",
    "            if tag_name not in tag_to_skip:\n",
    "                csv_file = os.path.join(path, info)\n",
    "                if tag_name == 'highlights_boundaries':\n",
    "                    data_value = np.genfromtxt(csv_file, delimiter=',', dtype=None)\n",
    "                else:\n",
    "                    data_value = np.fromfile(csv_file, dtype=np.float64)\n",
    "                data[tag_name] = data_value\n",
    "            data['name'] = game_name\n",
    "        games_data.append(data)\n",
    "\n",
    "games_backup = games_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### REMOVENDO VALORES CORRELACIONADOS ###\n",
    "\n",
    "to_remove = ['em_mcs_energy', 'em_mcs_energy_diff', 'em_mcs_energy_diff_ascending']\n",
    "for game in games_data:\n",
    "    for tag in to_remove:\n",
    "        del game[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/py3env/lib/python3.5/site-packages/ipykernel/__main__.py:27: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    }
   ],
   "source": [
    "### CRIANDO VETOR DE GT ###\n",
    "\n",
    "normal_cases = ['Normal', 'Inicio', 'Fim']\n",
    "to_skip = ['name', 'highlights_boundaries']\n",
    "\n",
    "for game in games_data:\n",
    "    h = game['highlights_boundaries']\n",
    "    end = h[-1][0]\n",
    "    gt = np.zeros(end)\n",
    "    slices = []\n",
    "    for line in h:\n",
    "        tag = line[2].decode('UTF-8').split(' ')\n",
    "        name = [t for t in tag if t != ''][0]\n",
    "        if name not in normal_cases:\n",
    "            gt[line[0]-1:line[1]] = 1\n",
    "        else:\n",
    "            slices.append([line[0], line[1], name])\n",
    "\n",
    "    slices = slices[::-1]\n",
    "    ## Removing data not to be considered ###\n",
    "    for k, values in game.items():\n",
    "        if k not in to_skip:\n",
    "            for sl in slices:\n",
    "                if 'Fim' in sl[2]:\n",
    "                    values = np.delete(values, range(sl[0], len(values)))\n",
    "                if 'Normal' in sl[2]:\n",
    "                    values = np.delete(values, range(sl[0], sl[1]))\n",
    "                if 'Inicio' in sl[2]:\n",
    "                    values = np.delete(values, range(0, sl[0]))\n",
    "        game[k] = values\n",
    "                    \n",
    "            \n",
    "    game['gt'] = gt\n",
    "    del game['highlights_boundaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CORTANDO VALORES EXCEDENTES PARA QUE TODOS OS DADOS TENHAM O MESMO TAMANHO ###\n",
    "\n",
    "for game in games_data:\n",
    "    values = [len(v) for k, v in game.items() if k not in ['name']]\n",
    "    min_l = min(values)\n",
    "    for k, v in game.items():\n",
    "        if len(v) > min_l:\n",
    "            game[k] = v[:min_l]\n",
    "            \n",
    "\n",
    "### ZERO PADDING ###\n",
    "max_length = 0\n",
    "for game in games_data:\n",
    "    values = [len(v) for k, v in game.items() if k not in ['name']]\n",
    "    max_length = max(values) if max(values)>max_length else max_length\n",
    "\n",
    "for game in games_data:\n",
    "    for k, v in game.items():\n",
    "        if k not in ['name']:\n",
    "            zero_v = np.zeros(max_length)\n",
    "            if len(v) < max_length:\n",
    "                zero_v[:len(v)] = v\n",
    "                game[k] = zero_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train: 22\n",
      "Total test: 5\n",
      "Total val: 2\n"
     ]
    }
   ],
   "source": [
    "### DIVIDING SPLITS FROM TRAIN, EVAL, TEST ###\n",
    "\n",
    "games_name = [g['name'] for g in games_data]\n",
    "games_train1, games_test = train_test_split(games_name, test_size=0.15)\n",
    "games_train2, games_val = train_test_split(games_train1, test_size=0.05)\n",
    "\n",
    "print('Total train: {}'.format(len(games_train2)))\n",
    "print('Total test: {}'.format(len(games_test)))\n",
    "print('Total val: {}'.format(len(games_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - dc_hue_mean\n",
      "1 - name\n",
      "2 - dc_percent\n",
      "3 - em_cs_energy\n",
      "4 - em_cs_energy_diff\n",
      "5 - em_cs_energy_diff_ascending\n",
      "6 - em_st_energy\n",
      "7 - em_st_energy_diff\n",
      "8 - em_st_energy_diff_ascending\n",
      "9 - pc_delta\n",
      "10 - pc_rho\n",
      "11 - pc_theta\n",
      "12 - pc_var_delta\n",
      "13 - pc_var_theta\n",
      "14 - pm_pitch\n",
      "15 - pm_pitch_diff\n",
      "16 - pm_pitch_diff_ascending\n",
      "17 - gt\n",
      "\n",
      "nome_id: 1, gt_id: 17\n"
     ]
    }
   ],
   "source": [
    "for i, tag_name in enumerate(games_data[10].keys()):\n",
    "    print('{} - {}'.format(i, tag_name))\n",
    "    if tag_name == 'name':\n",
    "        name_id = i\n",
    "    if tag_name == 'gt':\n",
    "        gt_id = i\n",
    "        \n",
    "print('\\nnome_id: {}, gt_id: {}'.format(name_id, gt_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (2000880, 16) (2000880,)\n",
      "Test (416850, 16) (416850,)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for game in games_data:\n",
    "    if game['name'] in games_train1:\n",
    "        values_array = list(game.values())\n",
    "        # Getting GT\n",
    "        y_train += list(values_array[gt_id])\n",
    "        \n",
    "        # Removing name and GT to train\n",
    "        del values_array[max(name_id, gt_id)]\n",
    "        del values_array[min(name_id, gt_id)]\n",
    "        \n",
    "        values_array = np.array(values_array)\n",
    "        if len(X_train) == 0:\n",
    "            X_train = np.transpose(values_array)\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, np.transpose(values_array)))\n",
    "y_train = np.array(y_train)    \n",
    "\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for game in games_data:\n",
    "    if game['name'] in games_test:\n",
    "        values_array = list(game.values())\n",
    "        # Getting GT\n",
    "        y_test += list(values_array[gt_id])\n",
    "        \n",
    "        # Removing name and GT to train\n",
    "        del values_array[max(name_id, gt_id)]\n",
    "        del values_array[min(name_id, gt_id)]\n",
    "        \n",
    "        values_array = np.array(values_array)\n",
    "        if len(X_test) == 0:\n",
    "            X_test = np.transpose(values_array)\n",
    "        else:\n",
    "            X_test = np.concatenate((X_test, np.transpose(values_array)))\n",
    "y_test = np.array(y_test)\n",
    "            \n",
    "\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/py3env/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing neural network with 1 layers, 16 inputs and 2 outputs.\n",
      "  - Dense: \u001b[1;97mSoftmax   \u001b[0m Units:  \u001b[1;97m2   \u001b[0m\n",
      "\n",
      "Training on dataset of 2,000,880 samples with 36,015,840 total size.\n",
      "  - Terminating loop after 25 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n"
     ]
    }
   ],
   "source": [
    "from sknn.mlp import Classifier, Layer\n",
    "import pickle\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "logging.basicConfig(\n",
    "            format=\"%(message)s\",\n",
    "            level=logging.DEBUG,\n",
    "            stream=sys.stdout)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('min/max scaler', MinMaxScaler(feature_range=(0.0, 1.0))),\n",
    "        ('neural network', Classifier(layers=[Layer(\"Softmax\")], n_iter=25))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "X_train_norm = pipeline.predict(X_train)\n",
    "X_test_norm = pipeline.predict(X_test)\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Maxout\", units=100, pieces=2),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=25,\n",
    "    verbose=True)\n",
    "\n",
    "w_train = numpy.array((X_train_norm.shape[0],))\n",
    "w_train[y_train == 0] = 1.02\n",
    "w_train[y_train == 1] = 50\n",
    "\n",
    "nn.fit(X_train_norm, y_train, w_train)\n",
    "nn.fit(X_train_norm, y_train)\n",
    "\n",
    "pickle.dump(nn, open('nn.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_scores = nn.predict(X_test_norm)\n",
    "y_prob = nn.predict_proba(X_test_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
