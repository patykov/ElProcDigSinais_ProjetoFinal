{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/py3env/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Theano was already imported and cannot be reconfigured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import collections\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from sknn.mlp import Classifier, Layer\n",
    "import pickle\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Use the maximum number of threads for this script.\n",
    "from sknn.platform import cpu32, threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### READING DATASET ###\n",
    "\n",
    "# Paths\n",
    "dataset_path = 'Dataset'\n",
    "games_dir = next(os.walk(dataset_path))[1]\n",
    "\n",
    "tag_to_skip = [\n",
    "    'highlights', 'highlights2', '.DS_Store', '.git', \n",
    "    'em_mcs_energy_diff_ascending', 'em_mcs_energy_diff', 'em_mcs_energy']\n",
    "\n",
    "# Iterating through games\n",
    "games_data = []\n",
    "games_path = [os.path.join(dataset_path, g) for g in games_dir]\n",
    "for path in games_path:\n",
    "    game_name = os.path.basename(path)\n",
    "    game_info = os.listdir(path)\n",
    "    data = collections.OrderedDict()\n",
    "    for info in game_info:\n",
    "        tag_name = os.path.splitext(info)[0]\n",
    "        if tag_name not in tag_to_skip:\n",
    "            csv_file = os.path.join(path, info)\n",
    "            if tag_name == 'highlights_boundaries':\n",
    "                data_value = np.genfromtxt(csv_file, delimiter=',', dtype=None)\n",
    "            else:\n",
    "                data_value = np.fromfile(csv_file, sep=' ')\n",
    "            data[tag_name] = data_value\n",
    "    data['name'] = game_name\n",
    "    games_data.append(data)\n",
    "\n",
    "games_backup = games_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CRIANDO VETOR DE GT ###\n",
    "\n",
    "wanted_cases = ['Gol', 'Perigo']\n",
    "to_skip = ['name', 'highlights_boundaries']\n",
    "\n",
    "for game in games_data:\n",
    "    h = game['highlights_boundaries']\n",
    "    end = h[-1][0]\n",
    "    gt = np.zeros(end)\n",
    "    for line in h:\n",
    "        tag = line[2].decode('UTF-8').split(' ')\n",
    "        name = [t for t in tag if t != ''][-1]\n",
    "        if name in wanted_cases:\n",
    "            gt[line[0]-1:line[1]] = 1                   \n",
    "            \n",
    "    game['gt'] = gt\n",
    "    del game['highlights_boundaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CORTANDO VALORES EXCEDENTES PARA QUE TODOS OS DADOS TENHAM O MESMO TAMANHO ###\n",
    "\n",
    "for game in games_data:\n",
    "    values = [len(v) for k, v in game.items() if k not in ['name']]\n",
    "    min_l = min(values)\n",
    "    for k, v in game.items():\n",
    "        if len(v) > min_l:\n",
    "            game[k] = v[:min_l]\n",
    "            \n",
    "\n",
    "### ZERO PADDING ###\n",
    "max_length = 0\n",
    "for game in games_data:\n",
    "    values = [len(v) for k, v in game.items() if k not in ['name']]\n",
    "    max_length = max(values) if max(values)>max_length else max_length\n",
    "\n",
    "for game in games_data:\n",
    "    for k, v in game.items():\n",
    "        if k not in ['name']:\n",
    "            zero_v = np.zeros(max_length)\n",
    "            if len(v) < max_length:\n",
    "                zero_v[:len(v)] = v\n",
    "                game[k] = zero_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train: 22\n",
      "Total test: 5\n",
      "Total val: 2\n"
     ]
    }
   ],
   "source": [
    "### DIVIDING SPLITS FROM TRAIN, EVAL, TEST ###\n",
    "\n",
    "games_name = [g['name'] for g in games_data]\n",
    "games_train1, games_test = train_test_split(games_name, test_size=0.15)\n",
    "games_train2, games_val = train_test_split(games_train1, test_size=0.05)\n",
    "\n",
    "print('Total train: {}'.format(len(games_train2)))\n",
    "print('Total test: {}'.format(len(games_test)))\n",
    "print('Total val: {}'.format(len(games_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - dc_hue_mean\n",
      "1 - name\n",
      "2 - dc_percent\n",
      "3 - em_cs_energy\n",
      "4 - em_cs_energy_diff\n",
      "5 - em_cs_energy_diff_ascending\n",
      "6 - em_st_energy\n",
      "7 - em_st_energy_diff\n",
      "8 - em_st_energy_diff_ascending\n",
      "9 - pc_delta\n",
      "10 - pc_rho\n",
      "11 - pc_theta\n",
      "12 - pc_var_delta\n",
      "13 - pc_var_theta\n",
      "14 - pm_pitch\n",
      "15 - pm_pitch_diff\n",
      "16 - pm_pitch_diff_ascending\n",
      "17 - gt\n",
      "\n",
      "nome_id: 1, gt_id: 17\n"
     ]
    }
   ],
   "source": [
    "def get_frames_ids(gt):\n",
    "    u, counts = np.unique(gt, return_counts=True)\n",
    "    ind_0 = [i for i, v in enumerate(gt) if v == 0.0]\n",
    "    ind_1 = [i for i, v in enumerate(gt) if v == 1.0]\n",
    "    \n",
    "    ind_0_ids = np.linspace(0, counts[0]-1, counts[1], dtype=int)\n",
    "    new_ind_0 = [ind_0[j] for j in ind_0_ids]\n",
    "    \n",
    "    return sorted(new_ind_0 + ind_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_matrix(restriction, skip):\n",
    "    data = []\n",
    "    gt = []\n",
    "    for game in games_data:\n",
    "        if game['name'] in restriction:\n",
    "            values_array = np.array(list(game.values()))\n",
    "\n",
    "            # Getting GT\n",
    "            gt_game = list(values_array[gt_id])\n",
    "\n",
    "            # Removing name and GT to train\n",
    "            values_array = np.delete(values_array, (max(name_id, gt_id)), axis=0)\n",
    "            values_array = np.delete(values_array, (min(name_id, gt_id)), axis=0)    \n",
    "\n",
    "            frames_ids = get_frames_ids(gt_game)\n",
    "            gt += [gt_game[i] for i in frames_ids]\n",
    "\n",
    "            game_features = []\n",
    "            for feature in values_array:\n",
    "                # Normalizing\n",
    "                norm_feature = np.squeeze(normalize([feature], axis=1))\n",
    "\n",
    "                M_feature = np.repeat([norm_feature], f_size, axis=0)\n",
    "                for i, v in enumerate(skip_values):\n",
    "                    M_feature[i] = np.roll(M_feature[i], v, axis=0)\n",
    "\n",
    "                M_feature = M_feature[:, frames_ids]\n",
    "\n",
    "                M_feature = np.transpose(M_feature)\n",
    "                if len(game_features) == 0:\n",
    "                    game_features = M_feature\n",
    "                else:\n",
    "                    game_features = np.concatenate((game_features, M_feature), axis=1)\n",
    "\n",
    "            if len(data) == 0:\n",
    "                data = game_features\n",
    "            else:\n",
    "                data = np.concatenate((data, game_features), axis=0)\n",
    "\n",
    "\n",
    "    gt = np.array(gt)\n",
    "    \n",
    "    return data, gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, tag_name in enumerate(games_data[10].keys()):\n",
    "    if tag_name == 'name':\n",
    "        name_id = i\n",
    "    if tag_name == 'gt':\n",
    "        gt_id = i\n",
    "\n",
    "skip = 8\n",
    "f_size = 61\n",
    "skip_values = np.arange(-30*skip, 31*skip, skip)\n",
    "\n",
    "X_train, y_train = get_matrix(games_train2, skip)\n",
    "\n",
    "X_test, y_test = get_matrix(games_test, skip)\n",
    "\n",
    "X_val, y_val = get_matrix(games_val, skip)\n",
    "\n",
    "\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Val', X_val.shape, y_val.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 16)) while a minimum of 1 is required by the normalize function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-028e5bb0b5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m     X = check_array(X, sparse_format, copy=copy,\n\u001b[0;32m-> 1412\u001b[0;31m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m   1413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    429\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 431\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 16)) while a minimum of 1 is required by the normalize function."
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for game in games_data:\n",
    "    if game['name'] in games_train2:\n",
    "        values_array = list(game.values())\n",
    "        # Getting GT\n",
    "        y_train += list(values_array[gt_id])\n",
    "        \n",
    "        # Removing name and GT to train\n",
    "        del values_array[max(name_id, gt_id)]\n",
    "        del values_array[min(name_id, gt_id)]\n",
    "        \n",
    "        values_array = np.array(values_array)\n",
    "        if len(X_train) == 0:\n",
    "            X_train = np.transpose(values_array)\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, np.transpose(values_array)))\n",
    "y_train = np.array(y_train)    \n",
    "\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for game in games_data:\n",
    "    if game['name'] in games_val:\n",
    "        values_array = list(game.values())\n",
    "        # Getting GT\n",
    "        y_val += list(values_array[gt_id])\n",
    "        \n",
    "        # Removing name and GT to train\n",
    "        del values_array[max(name_id, gt_id)]\n",
    "        del values_array[min(name_id, gt_id)]\n",
    "        \n",
    "        values_array = np.array(values_array)\n",
    "        if len(X_val) == 0:\n",
    "            X_val = np.transpose(values_array)\n",
    "        else:\n",
    "            X_val = np.concatenate((X_val, np.transpose(values_array)))\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for game in games_data:\n",
    "    if game['name'] in games_test:\n",
    "        values_array = list(game.values())\n",
    "        # Getting GT\n",
    "        y_test += list(values_array[gt_id])\n",
    "        \n",
    "        # Removing name and GT to train\n",
    "        del values_array[max(name_id, gt_id)]\n",
    "        del values_array[min(name_id, gt_id)]\n",
    "        \n",
    "        values_array = np.array(values_array)\n",
    "        if len(X_test) == 0:\n",
    "            X_test = np.transpose(values_array)\n",
    "        else:\n",
    "            X_test = np.concatenate((X_test, np.transpose(values_array)))\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "normalize(X_train, axis=1, copy=False)\n",
    "normalize(X_val, axis=1, copy=False)\n",
    "normalize(X_test, axis=1, copy=False)\n",
    "\n",
    "print('Train', X_train.shape, y_train.shape)\n",
    "print('Val', X_val.shape, y_val.shape)\n",
    "print('Test', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing neural network with 2 layers, 16 inputs and 2 outputs.\n",
      "  - Dense: \u001b[1;97mTanh      \u001b[0m Units:  \u001b[1;97m100 \u001b[0m\n",
      "  - Dense: \u001b[1;97mSoftmax   \u001b[0m Units:  \u001b[1;97m2   \u001b[0m\n",
      "\n",
      "Training on dataset of 1,834,140 samples with 33,014,520 total size.\n",
      "  - Train: 1,834,140  Valid: 166,740\n",
      "  - Terminating loop after 25 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n",
      "    1         \u001b[0;94m 1.045e+00\u001b[0m            \u001b[0;32m 4.516e-01\u001b[0m        238.3s\n",
      "    2         \u001b[0;94m 1.041e+00\u001b[0m            \u001b[0;32m 3.861e-01\u001b[0m        257.2s\n",
      "    3         \u001b[0;94m 1.039e+00\u001b[0m             4.738e-01        251.2s\n",
      "    4         \u001b[0;94m 1.040e+00\u001b[0m             4.258e-01        256.6s\n",
      "    5         \u001b[0;94m 1.040e+00\u001b[0m            \u001b[0;32m 3.364e-01\u001b[0m        245.6s\n",
      "    6         \u001b[0;94m 1.039e+00\u001b[0m             4.672e-01        478.2s\n",
      "    7         \u001b[0;94m 1.040e+00\u001b[0m             4.011e-01        1930.7s\n",
      "    8         \u001b[0;94m 1.040e+00\u001b[0m             5.227e-01        245.8s\n",
      "    9         \u001b[0;94m 1.040e+00\u001b[0m             3.864e-01        230.1s\n",
      "   10         \u001b[0;94m 1.040e+00\u001b[0m             3.923e-01        238.5s\n",
      "   11         \u001b[0;94m 1.039e+00\u001b[0m             4.883e-01        237.4s\n",
      "   12         \u001b[0;94m 1.039e+00\u001b[0m             5.331e-01        236.7s\n",
      "   13         \u001b[0;94m 1.039e+00\u001b[0m             4.002e-01        233.0s\n",
      "   14         \u001b[0;94m 1.039e+00\u001b[0m             4.196e-01        233.5s\n",
      "   15         \u001b[0;94m 1.039e+00\u001b[0m             4.017e-01        247.6s\n",
      "\n",
      "Early termination condition fired at 15 iterations.\n",
      "Training on dataset of 1,834,140 samples with 33,014,520 total size.\n",
      "  - Train: 1,834,140  Valid: 166,740\n",
      "  - Terminating loop after 25 total iterations.\n",
      "  - Early termination after 10 stable iterations.\n",
      "\n",
      "Epoch       Training Error       Validation Error       Time\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Bad input argument to theano function with name \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/backend/lasagne/mlp.py:98\" at index 2 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-a8345c708a1f>\", line 20, in <module>\n    nn.fit(X_train, y_train, w_train)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\", line 397, in fit\n    return super(Classifier, self)._fit(X, yp, w)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\", line 213, in _fit\n    X, y = self._initialize(X, y, w)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\", line 42, in _initialize\n    return self._backend._initialize_impl(X, y, w)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/backend/lasagne/mlp.py\", line 241, in _initialize_impl\n    self._create_mlp(X, w)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/backend/lasagne/mlp.py\", line 177, in _create_mlp\n    self.data_mask = T.vector('m') if w is not None else T.scalar('m')\nWrong number of dimensions: expected 1, got 0 with shape ().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a8345c708a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nn.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;31m# Now train based on a problem transformed into regression.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             log.error(\"\\n{}{}{}\\n\\n{}\\n\".format(\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mis_best_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mavg_train_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mavg_train_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_train_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/sknn/backend/lasagne/mlp.py\u001b[0m in \u001b[0;36m_train_impl\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_valid_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/sknn/backend/lasagne/mlp.py\u001b[0m in \u001b[0;36m_batch_impl\u001b[0;34m(self, X, y, w, processor, mode, output, shuffle)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    812\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/py3env/lib/python3.5/site-packages/theano/tensor/type.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    176\u001b[0m             raise TypeError(\"Wrong number of dimensions: expected %s,\"\n\u001b[1;32m    177\u001b[0m                             \" got %s with shape %s.\" % (self.ndim, data.ndim,\n\u001b[0;32m--> 178\u001b[0;31m                                                         data.shape))\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Bad input argument to theano function with name \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/backend/lasagne/mlp.py:98\" at index 2 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-a8345c708a1f>\", line 20, in <module>\n    nn.fit(X_train, y_train, w_train)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\", line 397, in fit\n    return super(Classifier, self)._fit(X, yp, w)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\", line 213, in _fit\n    X, y = self._initialize(X, y, w)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/mlp.py\", line 42, in _initialize\n    return self._backend._initialize_impl(X, y, w)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/backend/lasagne/mlp.py\", line 241, in _initialize_impl\n    self._create_mlp(X, w)\n  File \"/Users/admin/py3env/lib/python3.5/site-packages/sknn/backend/lasagne/mlp.py\", line 177, in _create_mlp\n    self.data_mask = T.vector('m') if w is not None else T.scalar('m')\nWrong number of dimensions: expected 1, got 0 with shape ()."
     ]
    }
   ],
   "source": [
    "\n",
    "logging.basicConfig(\n",
    "            format=\"%(message)s\",\n",
    "            level=logging.DEBUG,\n",
    "            stream=sys.stdout)\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Tanh\", units=100),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=25,\n",
    "    verbose=True,\n",
    "    valid_set=(X_val, y_val))\n",
    "\n",
    "w_train = np.zeros(X_train.shape[0])\n",
    "w_train[y_train == 0] = 1.02\n",
    "w_train[y_train == 1] = 50\n",
    "\n",
    "nn.fit(X_train, y_train, w_train)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "pickle.dump(nn, open('nn.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_scores = nn.predict(X_test_norm)\n",
    "y_prob = nn.predict_proba(X_test_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
